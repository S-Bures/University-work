{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## The Social Informatics of Large Language Models\n",
    "\n",
    "#### Claire Jordan, Sharon Bures, Elena Solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "openai.api_base=\"http://91.107.239.71:80\" #\"http://127.0.0.1:8000\"\n",
    "openai.api_key=\"\" # enter you API key here\n",
    "\n",
    "from tqdm import tqdm \n",
    "import time \n",
    "\n",
    "import json \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_techniques = [\"default\", \"blurry\", \"emotional\", \"chain_of_thought\", \"persona\"]\n",
    "topics = [\"matematical_logical\", \"coding\", \"moral_jailbreak\"]\n",
    "positioning = [\"beginning\", \"middle\", \"end\"]\n",
    "\n",
    "runs = 3\n",
    "\n",
    "\n",
    "\n",
    "# one dictionary per topic, storing the three positioning-prompts per technique\n",
    "\n",
    "math_dict = {'default' : [\"default_prompt_beginning\", \"default_prompt_middle\", \"default_prompt_end\"],\n",
    "             'blurry' : [\"blurry_prompt_beginning\", \"blurry_prompt_middle\", \"blurry_prompt_end\"],\n",
    "             'emotional' : [\"emotional_prompt_beginning\", \"emotional_prompt_middle\", \"emotional_prompt_end\"],\n",
    "             'chain_of_thought' : [\"cot_prompt_beginning\", \"cot_prompt_middle\", \"cot_prompt_end\"],\n",
    "             'persona' : [\"persona_prompt_beginning\", \"persona_prompt_middle\", \"persona_prompt_end\"],\n",
    "}\n",
    "\n",
    "\n",
    "coding_dict = {'default' : [\"default_prompt_beginning\", \"default_prompt_middle\", \"default_prompt_end\"],\n",
    "             'blurry' : [\"blurry_prompt_beginning\", \"blurry_prompt_middle\", \"blurry_prompt_end\"],\n",
    "             'emotional' : [\"emotional_prompt_beginning\", \"emotional_prompt_middle\", \"emotional_prompt_end\"],\n",
    "             'chain_of_thought' : [\"cot_prompt_beginning\", \"cot_prompt_middle\", \"cot_prompt_end\"],\n",
    "             'persona' : [\"persona_prompt_beginning\", \"persona_prompt_middle\", \"persona_prompt_end\"],\n",
    "}\n",
    "\n",
    "moral_dict = {'default' : [\"default_prompt_beginning\", \"default_prompt_middle\", \"default_prompt_end\"],\n",
    "             'blurry' : [\"blurry_prompt_beginning\", \"blurry_prompt_middle\", \"blurry_prompt_end\"],\n",
    "             'emotional' : [\"emotional_prompt_beginning\", \"emotional_prompt_middle\", \"emotional_prompt_end\"],\n",
    "             'chain_of_thought' : [\"cot_prompt_beginning\", \"cot_prompt_middle\", \"cot_prompt_end\"],\n",
    "             'persona' : [\"persona_prompt_beginning\", \"persona_prompt_middle\", \"persona_prompt_end\"],\n",
    "}\n",
    "\n",
    "# make one data frame from each dictionary\n",
    "math_prompts = pd.DataFrame(math_dict, columns = positioning)\n",
    "coding_prompts = pd.DataFrame(coding_dict, columns = positioning)\n",
    "moral_prompts = pd.DataFrame(moral_dict, columns = positioning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make prompt\n",
    "## probably not needed\n",
    "\n",
    "\n",
    "# def make_prompt(topic, prompt_technique, position):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Function to construct the prompt for the given topic, technique and positioning.\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#         topic: the topic which shall be asked (mathematical, coding or moral)\n",
    "#         prompt_technique: the prompt technique, that shall be used (default, blurry, emotional, chain of thought or persona)\n",
    "#         positioning: positioning of the important sentence (beginning, middle or end)\n",
    "\n",
    "#     Returns:\n",
    "#     --------\n",
    "#         prompt: the final prompt\n",
    "#     \"\"\"\n",
    "\n",
    "\n",
    "#     if topic == \"mathematical\":\n",
    "#         prompt = math_prompts[prompt_technique, position]\n",
    "#         return prompt\n",
    "\n",
    "#     elif topic == \"coding\":\n",
    "#         prompt = coding_prompts[prompt_technique, position]\n",
    "#         return prompt\n",
    "\n",
    "#     elif topic == \"moral\":\n",
    "#         prompt = moral_prompts[prompt_technique, position]\n",
    "#         return prompt\n",
    "\n",
    "#     else:\n",
    "#         # error, no valid topic given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call GPT (both versions)\n",
    "\n",
    "def call_GPT(topics, prompt_techniques, positions, gpt_model, runs):\n",
    "    \"\"\" \n",
    "    Function to call ChatGPT for classifying questions and scenarios as moral issues or not.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        topic: the topic which shall be asked (mathematical, coding or moral)\n",
    "        prompt_technique: the prompt technique, that shall be used (default, blurry, emotional, chain of thought or persona)\n",
    "        positioning: positioning of the important sentence (beginning, middle or end)\n",
    "        gpt_model: the version of gpt to use (gpt-3.5-turbo or gpt-4-1106-preview)\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "        result: Dictionary conatining all information (on inputs) an results\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize result dictionary\n",
    "    result = {'topic' : [],\n",
    "          'prompt_technique' : [],\n",
    "          'position' : [],\n",
    "          'run' : [],\n",
    "          'gpt_version' : [],\n",
    "          'answer' : [],\n",
    "          'tokens' : []}\n",
    "    \n",
    "    # process bar\n",
    "    total_iterations = len(topics) * len(prompt_techniques) * len(positions) * len(gpt_model) * len(runs)\n",
    "    progress_bar = tqdm(total=total_iterations, desc='Iterations')\n",
    "    iteration_counter = 0\n",
    "\n",
    "    for topic in topics: \n",
    "        for prompt_technique in prompt_techniques:\n",
    "            for position in positions: \n",
    "                \n",
    "                    \n",
    "                # make prompt \n",
    "                if topic == 'mathematics':\n",
    "                    prompt = math_prompts[prompt_technique, position]\n",
    "                \n",
    "                elif topic == 'coding':\n",
    "                    prompt = coding_prompts[prompt_technique, position]\n",
    "\n",
    "                elif topic == 'moral':\n",
    "                    prompt = moral_prompts[prompt_technique, position]\n",
    "                # 3 runs\n",
    "                for i in range(runs):\n",
    "\n",
    "                    try:\n",
    "                        resp = openai.ChatCompletion.create(model=gpt_model,\n",
    "                                            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                                            n=1)\n",
    "                        \n",
    "                        answer = resp['choices'][0]['message']['content']\n",
    "\n",
    "                        if gpt_model == 'gpt-3.5-turbo':\n",
    "                            tokens = resp['usage']['completion_tokens'] + resp['usage']['prompt_tokens']\n",
    "                        \n",
    "                        elif gpt_model == 'gpt-4-1106-preview':\n",
    "                            tokens = resp['usage']['completion_tokens'] * 15 + resp['usage']['prompt_tokens'] * 10\n",
    "\n",
    "                        # Append to result dictionary\n",
    "                        result['topic'].append(topic)\n",
    "                        result['prompt_technique'].append(prompt_technique)\n",
    "                        result['position'].append(position)\n",
    "                        result['run'].append(i + 1)\n",
    "                        result['gpt_version'].append(gpt_model)\n",
    "                        result['answer'].append(answer)\n",
    "                        result['tokens'].append(tokens)\n",
    "                            \n",
    "                        \n",
    "  \n",
    "\n",
    "                    except Exception as e:\n",
    "                        resp = e\n",
    "\n",
    "                       # Append to result dictionary\n",
    "                        result['topic'].append(topic)\n",
    "                        result['prompt_technique'].append(prompt_technique)\n",
    "                        result['position'].append(position)\n",
    "                        result['run'].append(i + 1)\n",
    "                        result['gpt_version'].append(gpt_model)\n",
    "                        result['answer'].append(f'Error: {e}')\n",
    "                        result['tokens'].append(tokens)\n",
    "                        \n",
    "                    \n",
    "                    iteration_counter += 1\n",
    "                    if iteration_counter % 10 == 0:  # Update progress bar every 10 iterations\n",
    "                        progress_bar.update(10)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
